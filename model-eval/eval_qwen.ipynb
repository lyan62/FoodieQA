{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=\"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 12:23:20,025 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-05-31 12:23:20,027 - modelscope - INFO - Loading ast index from /home/wenyanli/.cache/modelscope/ast_indexer\n",
      "2024-05-31 12:23:20,067 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 6642171ea0bed2a37aa087c81f13b239 and a total number of 976 components indexed\n",
      "/scratch3/wenyan/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-05-31 12:23:22,221 - modelscope - WARNING - Model revision not specified, use revision: v1.0.3\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61305e30c69e4802ba1121ffe8e83b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os \n",
    "\n",
    "os.environ['HF_HOME'] = '/scratch3/wenyan/cache'\n",
    "DEVICE = \"cuda:1\"\n",
    "\n",
    "# Downloading model checkpoint to a local dir model_dir\n",
    "model_dir = snapshot_download('qwen/Qwen-VL', cache_dir=os.environ['HF_HOME'])\n",
    "# model_dir = snapshot_download('qwen/Qwen-VL-Chat')\n",
    "\n",
    "\n",
    "# Loading local checkpoints\n",
    "# trust_remote_code is still set as True since we still load codes from local dir instead of transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True, do_image_splitting=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map=\"cuda\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 12:28:16,606 - modelscope - WARNING - Model revision not specified, use revision: v1.0.3\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130dc058c8c64d9c9f3610bd0e160f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## download model\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os \n",
    "\n",
    "os.environ['HF_HOME'] = '/scratch3/wenyan/cache'\n",
    "# DEVICE = \"cuda:1\"\n",
    "\n",
    "# Downloading model checkpoint to a local dir model_dir\n",
    "model_dir = snapshot_download('qwen/Qwen-VL', cache_dir=os.environ['HF_HOME'])\n",
    "# model_dir = snapshot_download('qwen/Qwen-VL-Chat')\n",
    "\n",
    "\n",
    "# Loading local checkpoints\n",
    "# trust_remote_code is still set as True since we still load codes from local dir instead of transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True, do_image_splitting=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load mutli-image vqa questions\n",
    "import json\n",
    "data_dir = \"/scratch3/wenyan/data/foodie\"\n",
    "question_file = os.path.join(data_dir, \"mivqa_filtered.json\")\n",
    "# mivqa = datasets.load_dataset('json', data_files=question_file)['train']\n",
    "with open(question_file, 'r') as f:\n",
    "    mivqa = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '哪一道菜中含有干贝？',\n",
       " 'choices': '',\n",
       " 'answer': '1',\n",
       " 'question_type': 'ingredients',\n",
       " 'question_id': '5cff42e986afc707c83ee411ae4af2e6_0',\n",
       " 'ann_group': '闽',\n",
       " 'images': ['14521898_all_202405061124164430/179_image.jpg',\n",
       "  '14521898_all_202405061124164430/208_IMG_5468.jpeg',\n",
       "  '14456664_all_202404292352223293/179_IMG_4221.jpeg',\n",
       "  '14456664_all_202404292352223293/188_57291912-AA46-487E-8EA0-01538BDAD35E.jpeg'],\n",
       " 'qid': 'mivqa-0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = mivqa[0]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_list(question, data_dir, template=0):\n",
    "    q = question[\"question\"].strip()\n",
    "    if template == 0:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = [{\"image\": os.path.join(data_dir, image)} for image in question[\"images\"]]\n",
    "        query_list.append({\"text\": \"根据以上四张图回答问题，他们分别为图A, 图B, 图C, 图D, 问题：{}, 答案为：图\".format(q)})\n",
    "    if template == 1:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = []\n",
    "        images = question[\"images\"]\n",
    "        idx2choice = {0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
    "        for i in range(len(images)):\n",
    "            query_list.append({\"image\" : os.path.join(data_dir, images[i])})\n",
    "            query_list.append({\"text\" : \"图{}\\n\".format(idx2choice[i])})\n",
    "        query_list.append({\"text\": \"根据以上四张图回答问题, 问题：{}, 答案为：图\".format(q)})\n",
    "    if template == 2:\n",
    "        query_list = [{\"text\":\"根据以下四张图回答问题,\"}]\n",
    "        images = question[\"images\"]\n",
    "        idx2choice = {0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
    "        for i in range(len(images)):\n",
    "            query_list.append({\"text\" : \"图{}\".format(idx2choice[i])})\n",
    "            query_list.append({\"image\" : os.path.join(data_dir, images[i])})\n",
    "        query_list.append({\"text\": \"问题：{}， 答案为：图\".format(question[\"question\"])})\n",
    "    if template == 3:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = [{\"image\": os.path.join(data_dir, image)} for image in question[\"images\"]]\n",
    "        query_list.append({\"text\": \"根据以上四张图回答问题, 问题：{}, 答案为：Picture\".format(question[\"question\"])})\n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_GENERAL = \"请从给定选项ABCD中选择一个最合适的答案。\"\n",
    "\n",
    "def get_query_list(question, data_dir, template=0):\n",
    "    q = question[\"question\"].strip()\n",
    "    idx2choice = {0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
    "    query_list = []\n",
    "    if template == 0:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = [{\"image\": os.path.join(data_dir, image)} for image in question[\"images\"]]\n",
    "        query_list.append({\"text\": \"根据以上四张图回答问题，他们分别为图A, 图B, 图C, 图D, \" + PROMPT_GENERAL + \"问题：{}, 答案为：图\".format(q)})\n",
    "    \n",
    "    if template == 1:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = []\n",
    "        images = question[\"images\"]\n",
    "        for i in range(len(images)):\n",
    "            query_list.append({\"image\" : os.path.join(data_dir, images[i])})\n",
    "            query_list.append({\"text\" : \"图{}\\n\".format(idx2choice[i])})\n",
    "        query_list.append({\"text\": \"根据以上四张图回答问题,\" + PROMPT_GENERAL + \"问题：{}, 答案为：图\".format(q)})\n",
    "    \n",
    "    if template == 2:\n",
    "        q = q.replace(\"以上\", \"以下\")\n",
    "        query_list = [{\"text\":\"根据以下四张图回答问题,\" + PROMPT_GENERAL}]\n",
    "        images = question[\"images\"]\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            query_list.append({\"text\" : \"图{}\".format(idx2choice[i])})\n",
    "            query_list.append({\"image\" : os.path.join(data_dir, images[i])})\n",
    "        query_list.append({\"text\": \"问题：{}, 答案为：图\".format(q)})\n",
    "    \n",
    "    if template == 3:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = [{\"image\": os.path.join(data_dir, image)} for image in question[\"images\"]]\n",
    "        query_list.append({\"text\": \"根据以上四张图回答问题, 问题：{}, 答案为：Picture\".format(q)})\n",
    "        \n",
    "    if template == 4:\n",
    "        q = q.replace(\"以下\", \"以上\")\n",
    "        query_list = [{\"text\": \"Human: 问题{}，选项有: \".format(q)}]\n",
    "        for i in range(len(images)):\n",
    "            query_list.append({\"text\" : \"图{}\".format(idx2choice[i])})\n",
    "            query_list.append({\"image\" : os.path.join(data_dir, images[i])})\n",
    "        query_list.append({\"text\": \"Assistant: 如果从给定选项ABCD中选择一个最合适的答案， 答案为：图\"})\n",
    "    return query_list\n",
    "\n",
    "def eval_question(mivqa, i, template=0):\n",
    "    question = mivqa[i]\n",
    "    query_list = get_query_list(question, data_dir, template=template)\n",
    "    query = tokenizer.from_list_format(query_list)\n",
    "    inputs = tokenizer(query, return_tensors='pt')\n",
    "    inputs = inputs.to(model.device)\n",
    "    pred = model.generate(**inputs)\n",
    "    response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=False)\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"qid\": mivqa[i][\"qid\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': '/scratch3/wenyan/data/foodie/14521898_all_202405061124164430/179_image.jpg'},\n",
       " {'image': '/scratch3/wenyan/data/foodie/14521898_all_202405061124164430/208_IMG_5468.jpeg'},\n",
       " {'image': '/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/179_IMG_4221.jpeg'},\n",
       " {'image': '/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/188_57291912-AA46-487E-8EA0-01538BDAD35E.jpeg'},\n",
       " {'text': '根据以上四张图回答问题，他们分别为图A, 图B, 图C, 图D, 请从给定选项ABCD中选择一个最合适的答案。问题：哪一道菜中含有干贝？, 答案为：图'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list1 = get_query_list(question, data_dir, template=0)\n",
    "query_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list2 = get_query_list(question, data_dir, template=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list3 = get_query_list(question, data_dir, template=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 1664, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "      (ln_pre): LayerNorm((1664,), eps=1e-06, elementwise_affine=True)\n",
       "      (transformer): TransformerBlock(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-47): 48 x VisualAttentionBlock(\n",
       "            (ln_1): LayerNorm((1664,), eps=1e-06, elementwise_affine=True)\n",
       "            (ln_2): LayerNorm((1664,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): VisualAttention(\n",
       "              (in_proj): Linear(in_features=1664, out_features=4992, bias=True)\n",
       "              (out_proj): Linear(in_features=1664, out_features=1664, bias=True)\n",
       "            )\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1664, out_features=8192, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=8192, out_features=1664, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attn_pool): Resampler(\n",
       "        (kv_proj): Linear(in_features=1664, out_features=4096, bias=False)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "        (ln_kv): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_post): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 1:<img>/scratch3/wenyan/data/foodie/14521898_all_202405061124164430/179_image.jpg</img>\n",
      "Picture 2:<img>/scratch3/wenyan/data/foodie/14521898_all_202405061124164430/208_IMG_5468.jpeg</img>\n",
      "Picture 3:<img>/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/179_IMG_4221.jpeg</img>\n",
      "Picture 4:<img>/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/188_57291912-AA46-487E-8EA0-01538BDAD35E.jpeg</img>\n",
      "根据以上四张图回答问题，他们分别为图A, 图B, 图C, 图D, 请从给定选项ABCD中选择一个最合适的答案。问题：哪一道菜中含有干贝？, 答案为：图B<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## example query input\n",
    "query = tokenizer.from_list_format(query_list1)\n",
    "inputs = tokenizer(query, return_tensors='pt')\n",
    "inputs = inputs.to(model.device)\n",
    "pred = model.generate(**inputs)\n",
    "response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=False)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Picture 1:<img>/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/104_IMG_0277.jpeg</img>\\nPicture 2:<img>/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/132_IMG_20220702_130156.jpg</img>\\nPicture 3:<img>/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/147_IMG_20190225_184723.jpg</img>\\nPicture 4:<img>/scratch3/wenyan/data/foodie/14456664_all_202404292352223293/151_IMG_20240414_200337.jpg</img>\\n根据以上四张图回答问题，他们分别为图A, 图B, 图C, 图D, 问题：哪一道菜的主料明显与别的菜不同？, 答案为：图'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def eval_qwen(mivqa, i, template=0):\n",
    "    question = mivqa[i]\n",
    "    query_list = get_query_list(question, data_dir, template=template)\n",
    "    query = tokenizer.from_list_format(query_list)\n",
    "    inputs = tokenizer(query, return_tensors='pt')\n",
    "    inputs = inputs.to(model.device)\n",
    "    pred = model.generate(**inputs)\n",
    "    response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=False)\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"qid\": mivqa[i][\"qid\"]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 140/403 [03:20<05:47,  1.32s/it]"
     ]
    }
   ],
   "source": [
    "with open(\"/scratch3/wenyan/data/foodie/mivqa_qwen_temp0.jsonl\", \"w\") as f:\n",
    "    for i in tqdm(range(len(mivqa))):\n",
    "        res = eval_qwen(mivqa, i, template=0)\n",
    "        f.write(json.dumps(res, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [09:18<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/scratch3/wenyan/data/foodie/mivqa_qwen_temp1.jsonl\", \"w\") as f:\n",
    "    for i in tqdm(range(len(mivqa))):\n",
    "        res = eval_qwen(mivqa, i, template=1)\n",
    "        f.write(json.dumps(res, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/scratch3/wenyan/data/foodie/mivqa_qwen_temp2.jsonl\", \"w\") as f:\n",
    "    for i in tqdm(range(len(mivqa))):\n",
    "        res = eval_qwen(mivqa, i, template=2)\n",
    "        f.write(json.dumps(res, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 403/403 [10:05<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/scratch3/wenyan/data/foodie/mivqa_qwen_temp3.jsonl\", \"w\") as f:\n",
    "    for i in tqdm(range(len(mivqa))):\n",
    "        res = eval_qwen(mivqa, i, template=3)\n",
    "        f.write(json.dumps(res, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"response\"].split(\"答案为：Picture\")[1].strip()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def parse_output(res, template=0):\n",
    "    ans2idx = {\n",
    "        \"A\":\"0\",\n",
    "        \"B\":\"1\",\n",
    "        \"C\":\"2\",\n",
    "        \"D\":\"3\"\n",
    "    }\n",
    "    \n",
    "    if template == 3:\n",
    "        ans = res[\"response\"].split(\"答案为：Picture\")[1].strip()[0]\n",
    "        return ans\n",
    "    else:\n",
    "        return ans2idx[ans.upper()]\n",
    "\n",
    "def get_accuracy(result_file, mivqa, template):\n",
    "    # get gts\n",
    "    gt = [x[\"answer\"] for x in mivqa]\n",
    "    \n",
    "    # get all answers\n",
    "    data = []\n",
    "    with open(result_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    ## get answers\n",
    "    all_answers = []\n",
    "    for d in data:\n",
    "        try:\n",
    "            ans = parse_output(d, template=template)\n",
    "            all_answers.append(ans)\n",
    "        except:\n",
    "            print(d[\"qid\"], d)\n",
    "    \n",
    "    accuracy = accuracy_score(all_answers, gt)\n",
    "    print(\"accuracy is: \", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  0.1513647642679901\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(\"/scratch3/wenyan/data/foodie/mivqa_qwen_temp3.jsonl\", mivqa, template=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
